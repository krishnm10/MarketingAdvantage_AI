"""init schema

Revision ID: ffdf38919f9c
Revises: 
Create Date: 2025-11-21 22:41:29.718580

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'ffdf38919f9c'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('idx_taxonomy_alias_unique'), table_name='taxonomy_alias')
    op.drop_table('taxonomy_alias')
    op.drop_table('business_classification')
    op.drop_index(op.f('idx_business_taxonomy_relationship_type'), table_name='business_taxonomy')
    op.drop_index(op.f('idx_business_taxonomy_source'), table_name='business_taxonomy')
    op.drop_index(op.f('idx_business_taxonomy_unique'), table_name='business_taxonomy')
    op.drop_table('business_taxonomy')
    op.drop_index(op.f('idx_pending_taxonomy_canonical_trgm'), table_name='pending_taxonomy', postgresql_ops={'canonical_name': 'gin_trgm_ops'}, postgresql_using='gin')
    op.drop_index(op.f('idx_pending_taxonomy_status'), table_name='pending_taxonomy')
    op.drop_table('pending_taxonomy')
    op.drop_table('classification_logs')
    op.drop_index(op.f('idx_taxonomy_canonical_name_trgm'), table_name='taxonomy', postgresql_ops={'canonical_name': 'gin_trgm_ops'}, postgresql_using='gin')
    op.drop_index(op.f('idx_taxonomy_level'), table_name='taxonomy')
    op.drop_index(op.f('idx_taxonomy_parent_id'), table_name='taxonomy')
    op.drop_table('taxonomy')
    op.alter_column('global_content_index', 'semantic_hash',
               existing_type=sa.VARCHAR(length=256),
               type_=sa.String(length=128),
               existing_nullable=False)
    op.alter_column('global_content_index', 'tokens',
               existing_type=sa.INTEGER(),
               nullable=False,
               existing_server_default=sa.text('0'))
    op.alter_column('global_content_index', 'meta_data',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True,
               existing_server_default=sa.text("'{}'::jsonb"))
    op.drop_constraint(op.f('global_content_index_semantic_hash_key'), 'global_content_index', type_='unique')
    op.drop_index(op.f('idx_gci_business_id'), table_name='global_content_index')
    op.drop_index(op.f('idx_gci_semhash'), table_name='global_content_index')
    op.drop_index(op.f('idx_gci_source_type'), table_name='global_content_index')
    op.create_index(op.f('ix_global_content_index_semantic_hash'), 'global_content_index', ['semantic_hash'], unique=True)
    op.drop_constraint(op.f('global_content_index_first_seen_file_id_fkey'), 'global_content_index', type_='foreignkey')
    op.drop_column('global_content_index', 'source_type')
    op.drop_column('global_content_index', 'business_id')
    op.drop_column('global_content_index', 'raw_text')
    op.drop_column('global_content_index', 'first_seen_file_id')
    op.alter_column('ingested_content', 'semantic_hash',
               existing_type=sa.TEXT(),
               type_=sa.String(length=256),
               existing_nullable=False)
    op.alter_column('ingested_content', 'source_type',
               existing_type=sa.TEXT(),
               type_=sa.String(length=50),
               nullable=True)
    op.alter_column('ingested_content', 'meta_data',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True,
               existing_server_default=sa.text("'{}'::jsonb"))
    op.drop_index(op.f('idx_ingested_content_business_id'), table_name='ingested_content')
    op.drop_index(op.f('idx_ingested_content_confidence'), table_name='ingested_content')
    op.drop_index(op.f('idx_ingested_content_file_id'), table_name='ingested_content')
    op.drop_index(op.f('idx_ingested_content_source_type'), table_name='ingested_content')
    op.drop_constraint(op.f('ingested_content_file_id_chunk_index_key'), 'ingested_content', type_='unique')
    op.drop_constraint(op.f('ingested_content_semantic_hash_key'), 'ingested_content', type_='unique')
    op.create_index(op.f('ix_ingested_content_semantic_hash'), 'ingested_content', ['semantic_hash'], unique=False)
    op.create_foreign_key(None, 'ingested_content', 'global_content_index', ['global_content_id'], ['id'])
    op.alter_column('ingested_file', 'file_name',
               existing_type=sa.TEXT(),
               type_=sa.String(length=255),
               existing_nullable=False)
    op.alter_column('ingested_file', 'file_type',
               existing_type=sa.TEXT(),
               type_=sa.String(length=50),
               existing_nullable=False)
    op.alter_column('ingested_file', 'file_path',
               existing_type=sa.TEXT(),
               type_=sa.String(length=1024),
               existing_nullable=True)
    op.alter_column('ingested_file', 'source_url',
               existing_type=sa.TEXT(),
               type_=sa.String(length=1024),
               existing_nullable=True)
    op.alter_column('ingested_file', 'meta_data',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True,
               existing_server_default=sa.text("'{}'::jsonb"))
    op.alter_column('ingested_file', 'status',
               existing_type=sa.TEXT(),
               type_=sa.String(length=50),
               nullable=False,
               existing_server_default=sa.text("'processed'::text"))
    op.drop_index(op.f('idx_ingested_file_business_id'), table_name='ingested_file')
    op.drop_index(op.f('idx_ingested_file_file_type'), table_name='ingested_file')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_index(op.f('idx_ingested_file_file_type'), 'ingested_file', ['file_type'], unique=False)
    op.create_index(op.f('idx_ingested_file_business_id'), 'ingested_file', ['business_id'], unique=False)
    op.alter_column('ingested_file', 'status',
               existing_type=sa.String(length=50),
               type_=sa.TEXT(),
               nullable=True,
               existing_server_default=sa.text("'processed'::text"))
    op.alter_column('ingested_file', 'meta_data',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True,
               existing_server_default=sa.text("'{}'::jsonb"))
    op.alter_column('ingested_file', 'source_url',
               existing_type=sa.String(length=1024),
               type_=sa.TEXT(),
               existing_nullable=True)
    op.alter_column('ingested_file', 'file_path',
               existing_type=sa.String(length=1024),
               type_=sa.TEXT(),
               existing_nullable=True)
    op.alter_column('ingested_file', 'file_type',
               existing_type=sa.String(length=50),
               type_=sa.TEXT(),
               existing_nullable=False)
    op.alter_column('ingested_file', 'file_name',
               existing_type=sa.String(length=255),
               type_=sa.TEXT(),
               existing_nullable=False)
    op.drop_constraint(None, 'ingested_content', type_='foreignkey')
    op.drop_index(op.f('ix_ingested_content_semantic_hash'), table_name='ingested_content')
    op.create_unique_constraint(op.f('ingested_content_semantic_hash_key'), 'ingested_content', ['semantic_hash'], postgresql_nulls_not_distinct=False)
    op.create_unique_constraint(op.f('ingested_content_file_id_chunk_index_key'), 'ingested_content', ['file_id', 'chunk_index'], postgresql_nulls_not_distinct=False)
    op.create_index(op.f('idx_ingested_content_source_type'), 'ingested_content', ['source_type'], unique=False)
    op.create_index(op.f('idx_ingested_content_file_id'), 'ingested_content', ['file_id'], unique=False)
    op.create_index(op.f('idx_ingested_content_confidence'), 'ingested_content', ['confidence'], unique=False)
    op.create_index(op.f('idx_ingested_content_business_id'), 'ingested_content', ['business_id'], unique=False)
    op.alter_column('ingested_content', 'meta_data',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True,
               existing_server_default=sa.text("'{}'::jsonb"))
    op.alter_column('ingested_content', 'source_type',
               existing_type=sa.String(length=50),
               type_=sa.TEXT(),
               nullable=False)
    op.alter_column('ingested_content', 'semantic_hash',
               existing_type=sa.String(length=256),
               type_=sa.TEXT(),
               existing_nullable=False)
    op.add_column('global_content_index', sa.Column('first_seen_file_id', sa.UUID(), autoincrement=False, nullable=True))
    op.add_column('global_content_index', sa.Column('raw_text', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('global_content_index', sa.Column('business_id', sa.UUID(), autoincrement=False, nullable=True))
    op.add_column('global_content_index', sa.Column('source_type', sa.VARCHAR(length=50), autoincrement=False, nullable=True))
    op.create_foreign_key(op.f('global_content_index_first_seen_file_id_fkey'), 'global_content_index', 'ingested_file', ['first_seen_file_id'], ['id'])
    op.drop_index(op.f('ix_global_content_index_semantic_hash'), table_name='global_content_index')
    op.create_index(op.f('idx_gci_source_type'), 'global_content_index', ['source_type'], unique=False)
    op.create_index(op.f('idx_gci_semhash'), 'global_content_index', ['semantic_hash'], unique=False)
    op.create_index(op.f('idx_gci_business_id'), 'global_content_index', ['business_id'], unique=False)
    op.create_unique_constraint(op.f('global_content_index_semantic_hash_key'), 'global_content_index', ['semantic_hash'], postgresql_nulls_not_distinct=False)
    op.alter_column('global_content_index', 'meta_data',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True,
               existing_server_default=sa.text("'{}'::jsonb"))
    op.alter_column('global_content_index', 'tokens',
               existing_type=sa.INTEGER(),
               nullable=True,
               existing_server_default=sa.text('0'))
    op.alter_column('global_content_index', 'semantic_hash',
               existing_type=sa.String(length=128),
               type_=sa.VARCHAR(length=256),
               existing_nullable=False)
    op.create_table('taxonomy',
    sa.Column('id', sa.UUID(), server_default=sa.text('uuid_generate_v4()'), autoincrement=False, nullable=False),
    sa.Column('name', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('canonical_name', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('parent_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('level', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('slug', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('meta_data', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=True),
    sa.Column('embedding_id', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.CheckConstraint('level = ANY (ARRAY[0, 1, 2])', name='taxonomy_level_check'),
    sa.ForeignKeyConstraint(['parent_id'], ['taxonomy.id'], name='taxonomy_parent_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='taxonomy_pkey'),
    sa.UniqueConstraint('canonical_name', name='taxonomy_canonical_name_key', postgresql_include=[], postgresql_nulls_not_distinct=False),
    postgresql_ignore_search_path=False
    )
    op.create_index(op.f('idx_taxonomy_parent_id'), 'taxonomy', ['parent_id'], unique=False)
    op.create_index(op.f('idx_taxonomy_level'), 'taxonomy', ['level'], unique=False)
    op.create_index(op.f('idx_taxonomy_canonical_name_trgm'), 'taxonomy', ['canonical_name'], unique=False, postgresql_ops={'canonical_name': 'gin_trgm_ops'}, postgresql_using='gin')
    op.create_table('classification_logs',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('content_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('taxonomy_path', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('confidence', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('embed_scores', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('llm_scores', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['content_id'], ['ingested_content.id'], name=op.f('classification_logs_content_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('classification_logs_pkey'))
    )
    op.create_table('pending_taxonomy',
    sa.Column('id', sa.UUID(), server_default=sa.text('uuid_generate_v4()'), autoincrement=False, nullable=False),
    sa.Column('raw_name', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('canonical_name', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('suggested_parent_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('suggested_level', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('similar_existing_ids', postgresql.ARRAY(sa.TEXT()), autoincrement=False, nullable=True),
    sa.Column('confidence', sa.DOUBLE_PRECISION(precision=53), server_default=sa.text('0.0'), autoincrement=False, nullable=True),
    sa.Column('status', sa.TEXT(), server_default=sa.text("'pending'::text"), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('level', sa.VARCHAR(length=32), server_default=sa.text("'industry'::character varying"), autoincrement=False, nullable=False),
    sa.Column('detected_from_chunk', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('llm_reason', sa.TEXT(), autoincrement=False, nullable=True),
    sa.CheckConstraint("status = ANY (ARRAY['pending'::text, 'approved'::text, 'rejected'::text])", name='pending_taxonomy_status_check'),
    sa.CheckConstraint('suggested_level = ANY (ARRAY[0, 1, 2])', name='pending_taxonomy_suggested_level_check'),
    sa.ForeignKeyConstraint(['detected_from_chunk'], ['ingested_content.id'], name='pending_taxonomy_detected_from_chunk_fkey'),
    sa.ForeignKeyConstraint(['suggested_parent_id'], ['taxonomy.id'], name='pending_taxonomy_suggested_parent_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='pending_taxonomy_pkey'),
    postgresql_ignore_search_path=False
    )
    op.create_index(op.f('idx_pending_taxonomy_status'), 'pending_taxonomy', ['status'], unique=False)
    op.create_index(op.f('idx_pending_taxonomy_canonical_trgm'), 'pending_taxonomy', ['canonical_name'], unique=False, postgresql_ops={'canonical_name': 'gin_trgm_ops'}, postgresql_using='gin')
    op.create_table('business_taxonomy',
    sa.Column('id', sa.UUID(), server_default=sa.text('uuid_generate_v4()'), autoincrement=False, nullable=False),
    sa.Column('business_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('taxonomy_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('relationship_type', sa.TEXT(), server_default=sa.text("'primary'::text"), autoincrement=False, nullable=False),
    sa.Column('confidence', sa.DOUBLE_PRECISION(precision=53), server_default=sa.text('1.0'), autoincrement=False, nullable=True),
    sa.Column('source', sa.TEXT(), server_default=sa.text("'manual'::text"), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['taxonomy_id'], ['taxonomy.id'], name=op.f('business_taxonomy_taxonomy_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('business_taxonomy_pkey'))
    )
    op.create_index(op.f('idx_business_taxonomy_unique'), 'business_taxonomy', ['business_id', 'taxonomy_id'], unique=True)
    op.create_index(op.f('idx_business_taxonomy_source'), 'business_taxonomy', ['source'], unique=False)
    op.create_index(op.f('idx_business_taxonomy_relationship_type'), 'business_taxonomy', ['relationship_type'], unique=False)
    op.create_table('business_classification',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('content_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('industry_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('sub_industry_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('sub_sub_industry_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('pending_taxonomy_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('confidence', sa.DOUBLE_PRECISION(precision=53), server_default=sa.text('0'), autoincrement=False, nullable=False),
    sa.Column('llm_model', sa.VARCHAR(length=64), server_default=sa.text("'llama-3.1-8b-instruct'::character varying"), autoincrement=False, nullable=True),
    sa.Column('raw_output', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['content_id'], ['ingested_content.id'], name=op.f('business_classification_content_id_fkey'), ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['industry_id'], ['taxonomy.id'], name=op.f('business_classification_industry_id_fkey')),
    sa.ForeignKeyConstraint(['pending_taxonomy_id'], ['pending_taxonomy.id'], name=op.f('business_classification_pending_taxonomy_id_fkey')),
    sa.ForeignKeyConstraint(['sub_industry_id'], ['taxonomy.id'], name=op.f('business_classification_sub_industry_id_fkey')),
    sa.ForeignKeyConstraint(['sub_sub_industry_id'], ['taxonomy.id'], name=op.f('business_classification_sub_sub_industry_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('business_classification_pkey'))
    )
    op.create_table('taxonomy_alias',
    sa.Column('id', sa.UUID(), server_default=sa.text('uuid_generate_v4()'), autoincrement=False, nullable=False),
    sa.Column('alias_name', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('canonical_taxonomy_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['canonical_taxonomy_id'], ['taxonomy.id'], name=op.f('taxonomy_alias_canonical_taxonomy_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('taxonomy_alias_pkey'))
    )
    op.create_index(op.f('idx_taxonomy_alias_unique'), 'taxonomy_alias', ['alias_name', 'canonical_taxonomy_id'], unique=True)
    # ### end Alembic commands ###
